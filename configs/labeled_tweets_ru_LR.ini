[main parameters]
model_type = LR
attack_type = TextAttack
dataset_filename = labeled_tweets_clean_normalized.csv
language = ru
vectorization_type = TFIDF1

[columns name]
text_column = text
label_column = toxic

[dataset splitting parameters]
test_size = .3

[model creation options]
solver = lbfgs


